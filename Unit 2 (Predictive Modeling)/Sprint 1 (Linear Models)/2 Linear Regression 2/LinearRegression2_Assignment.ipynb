{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of LS_DS_212_solution.ipynb","provenance":[{"file_id":"https://github.com/LambdaSchool/DS-Unit-2-Linear-Models/blob/master/module2-regression-2/LS_DS_212_assignment.ipynb","timestamp":1635127651834}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_Al1M8zvM-BK"},"source":["Lambda School Data Science\n","\n","*Unit 2, Sprint 1, Module 2*\n","\n","---"]},{"cell_type":"code","metadata":{"id":"zGXjmjg7M-BN"},"source":["%%capture\n","import sys\n","\n","# If you're on Colab:\n","if 'google.colab' in sys.modules:\n","    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n","\n","# If you're working locally:\n","else:\n","    DATA_PATH = '../data/'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tCsbll8LM-BP"},"source":["# Module Project: Regression II\n","\n","In this project, you'll continue working with the New York City rent dataset you used in the last module project.\n","\n","## Directions\n","\n","The tasks for this project are as follows:\n","\n","- **Task 1:** Import `csv` file using `wrangle` function.\n","- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function to engineer two new features.\n","- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n","- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n","- **Task 5:** Establish the baseline mean absolute error for your dataset.\n","- **Task 6:** Build and train a `Linearregression` model.\n","- **Task 7:** Calculate the training and test mean absolute error for your model.\n","- **Task 8:** Calculate the training and test $R^2$ score for your model.\n","- **Stretch Goal:** Determine the three most important features for your linear regression model.\n","\n","**Note**\n","\n","You should limit yourself to the following libraries for this project:\n","\n","- `matplotlib`\n","- `numpy`\n","- `pandas`\n","- `sklearn`"]},{"cell_type":"code","metadata":{"id":"hSj-6fywUIjq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635294225351,"user_tz":240,"elapsed":3477,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"83d42f1f-a713-4c80-fbbd-b029edacc92d"},"source":["import pandas as pd\n","import numpy as np\n","!pip install category_encoders==2.*\n","from category_encoders import OneHotEncoder"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: category_encoders==2.* in /usr/local/lib/python3.7/dist-packages (2.3.0)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.5.2)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.22.2.post1)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.19.5)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (0.10.2)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders==2.*) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.0.1)\n"]}]},{"cell_type":"markdown","metadata":{"id":"yTj5GrT_M-BQ"},"source":["# I. Wrangle Data"]},{"cell_type":"code","metadata":{"id":"h2RW5sFZM-BQ"},"source":["def wrangle(filepath):\n","    df = pd.read_csv(filepath,\n","                     parse_dates=['created'],\n","                     index_col='created')\n","    df.dropna(inplace=True)\n","    \n","    # Remove the most extreme 1% prices,\n","    # the most extreme .1% latitudes, &\n","    # the most extreme .1% longitudes\n","    df = df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n","            (df['price'] <= np.percentile(df['price'], 99.5)) & \n","            (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n","            (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n","            (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n","            (df['longitude'] <= np.percentile(df['longitude'], 99.95))]\n","    \n","    #Adding New features\n","    df['total_perks'] = df[df.columns[9:]].sum(axis=1)\n","    df['total_rooms'] = df['bathrooms'] + df['bedrooms']\n","\n","    df.drop(columns=['description',\t'display_address',\t'street_address'], inplace=True)\n","\n","    # Instantiating the encoder as an object and\n","    # create columns Using the fit_transform method\n","    encoder = OneHotEncoder(use_cat_names=True)\n","    encoder.fit(df)\n","    df = encoder.transform(df) \n","\n","    return df\n","\n","filepath = DATA_PATH + 'apartments/renthop-nyc.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ofhS-CGIM-BR"},"source":["**Task 1:** Add the following functionality to the above `wrangle` function.\n","\n","- The `'created'` column will parsed as a `DateTime` object and set as the `index` of the DataFrame. \n","- Rows with `NaN` values will be dropped.\n","\n","Then use your modified function to import the `renthop-nyc.csv` file into a DataFrame named `df`."]},{"cell_type":"code","metadata":{"id":"fxXisbhUM-BR"},"source":["df = wrangle(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7SksaA3M-BS"},"source":["**Task 2:** Using your `pandas` and dataviz skills decide on two features that you want to engineer for your dataset. Next, modify your `wrangle` function to add those features. \n","\n","**Note:** You can learn more about feature engineering [here](https://en.wikipedia.org/wiki/Feature_engineering). Here are some ideas for new features:\n","\n","- Does the apartment have a description?\n","- Length of description.\n","- Total number of perks that apartment has.\n","- Are cats _or_ dogs allowed?\n","- Are cats _and_ dogs allowed?\n","- Total number of rooms (beds + baths)."]},{"cell_type":"code","metadata":{"id":"v9JKg9hoM-BT","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1635294227016,"user_tz":240,"elapsed":285,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"10bf1149-109f-4cf6-d2f7-ddfae4afc7d0"},"source":["# Conduct your exploratory data analysis here, \n","# and then modify the function above.\n","\n","df.head()\n","df.info()\n","df.describe()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","DatetimeIndex: 47260 entries, 2016-06-24 07:54:24 to 2016-04-12 02:48:07\n","Data columns (total 34 columns):\n"," #   Column                 Non-Null Count  Dtype  \n","---  ------                 --------------  -----  \n"," 0   bathrooms              47260 non-null  float64\n"," 1   bedrooms               47260 non-null  int64  \n"," 2   latitude               47260 non-null  float64\n"," 3   longitude              47260 non-null  float64\n"," 4   price                  47260 non-null  int64  \n"," 5   interest_level_medium  47260 non-null  int64  \n"," 6   interest_level_low     47260 non-null  int64  \n"," 7   interest_level_high    47260 non-null  int64  \n"," 8   elevator               47260 non-null  int64  \n"," 9   cats_allowed           47260 non-null  int64  \n"," 10  hardwood_floors        47260 non-null  int64  \n"," 11  dogs_allowed           47260 non-null  int64  \n"," 12  doorman                47260 non-null  int64  \n"," 13  dishwasher             47260 non-null  int64  \n"," 14  no_fee                 47260 non-null  int64  \n"," 15  laundry_in_building    47260 non-null  int64  \n"," 16  fitness_center         47260 non-null  int64  \n"," 17  pre-war                47260 non-null  int64  \n"," 18  laundry_in_unit        47260 non-null  int64  \n"," 19  roof_deck              47260 non-null  int64  \n"," 20  outdoor_space          47260 non-null  int64  \n"," 21  dining_room            47260 non-null  int64  \n"," 22  high_speed_internet    47260 non-null  int64  \n"," 23  balcony                47260 non-null  int64  \n"," 24  swimming_pool          47260 non-null  int64  \n"," 25  new_construction       47260 non-null  int64  \n"," 26  terrace                47260 non-null  int64  \n"," 27  exclusive              47260 non-null  int64  \n"," 28  loft                   47260 non-null  int64  \n"," 29  garden_patio           47260 non-null  int64  \n"," 30  wheelchair_access      47260 non-null  int64  \n"," 31  common_outdoor_space   47260 non-null  int64  \n"," 32  total_perks            47260 non-null  int64  \n"," 33  total_rooms            47260 non-null  float64\n","dtypes: float64(4), int64(30)\n","memory usage: 12.6 MB\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bathrooms</th>\n","      <th>bedrooms</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>price</th>\n","      <th>interest_level_medium</th>\n","      <th>interest_level_low</th>\n","      <th>interest_level_high</th>\n","      <th>elevator</th>\n","      <th>cats_allowed</th>\n","      <th>hardwood_floors</th>\n","      <th>dogs_allowed</th>\n","      <th>doorman</th>\n","      <th>dishwasher</th>\n","      <th>no_fee</th>\n","      <th>laundry_in_building</th>\n","      <th>fitness_center</th>\n","      <th>pre-war</th>\n","      <th>laundry_in_unit</th>\n","      <th>roof_deck</th>\n","      <th>outdoor_space</th>\n","      <th>dining_room</th>\n","      <th>high_speed_internet</th>\n","      <th>balcony</th>\n","      <th>swimming_pool</th>\n","      <th>new_construction</th>\n","      <th>terrace</th>\n","      <th>exclusive</th>\n","      <th>loft</th>\n","      <th>garden_patio</th>\n","      <th>wheelchair_access</th>\n","      <th>common_outdoor_space</th>\n","      <th>total_perks</th>\n","      <th>total_rooms</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.00000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","      <td>47260.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1.203364</td>\n","      <td>1.544012</td>\n","      <td>40.750689</td>\n","      <td>-73.972736</td>\n","      <td>3578.041536</td>\n","      <td>0.234596</td>\n","      <td>0.688574</td>\n","      <td>0.076830</td>\n","      <td>0.521075</td>\n","      <td>0.474884</td>\n","      <td>0.492044</td>\n","      <td>0.443377</td>\n","      <td>0.426153</td>\n","      <td>0.424799</td>\n","      <td>0.377359</td>\n","      <td>0.052751</td>\n","      <td>0.268240</td>\n","      <td>0.191727</td>\n","      <td>0.180470</td>\n","      <td>0.137050</td>\n","      <td>0.141832</td>\n","      <td>0.106073</td>\n","      <td>0.090055</td>\n","      <td>0.060559</td>\n","      <td>0.057025</td>\n","      <td>0.053618</td>\n","      <td>0.04744</td>\n","      <td>0.032628</td>\n","      <td>0.044033</td>\n","      <td>0.040626</td>\n","      <td>0.028121</td>\n","      <td>0.026280</td>\n","      <td>4.718218</td>\n","      <td>2.747376</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.472804</td>\n","      <td>1.108318</td>\n","      <td>0.038839</td>\n","      <td>0.028964</td>\n","      <td>1765.210584</td>\n","      <td>0.423750</td>\n","      <td>0.463081</td>\n","      <td>0.266325</td>\n","      <td>0.499561</td>\n","      <td>0.499374</td>\n","      <td>0.499942</td>\n","      <td>0.496789</td>\n","      <td>0.494522</td>\n","      <td>0.494318</td>\n","      <td>0.484731</td>\n","      <td>0.223538</td>\n","      <td>0.443048</td>\n","      <td>0.393663</td>\n","      <td>0.384582</td>\n","      <td>0.343904</td>\n","      <td>0.348882</td>\n","      <td>0.307934</td>\n","      <td>0.286264</td>\n","      <td>0.238521</td>\n","      <td>0.231893</td>\n","      <td>0.225265</td>\n","      <td>0.21258</td>\n","      <td>0.177663</td>\n","      <td>0.205171</td>\n","      <td>0.197425</td>\n","      <td>0.165320</td>\n","      <td>0.159969</td>\n","      <td>3.439983</td>\n","      <td>1.414901</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>40.575700</td>\n","      <td>-74.087300</td>\n","      <td>1375.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>40.728200</td>\n","      <td>-73.991800</td>\n","      <td>2500.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>40.751600</td>\n","      <td>-73.978000</td>\n","      <td>3150.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>4.000000</td>\n","      <td>2.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1.000000</td>\n","      <td>2.000000</td>\n","      <td>40.773900</td>\n","      <td>-73.955000</td>\n","      <td>4095.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.00000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.000000</td>\n","      <td>4.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>10.000000</td>\n","      <td>8.000000</td>\n","      <td>40.989400</td>\n","      <td>-73.700100</td>\n","      <td>15500.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.00000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>19.000000</td>\n","      <td>12.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          bathrooms      bedrooms  ...   total_perks   total_rooms\n","count  47260.000000  47260.000000  ...  47260.000000  47260.000000\n","mean       1.203364      1.544012  ...      4.718218      2.747376\n","std        0.472804      1.108318  ...      3.439983      1.414901\n","min        0.000000      0.000000  ...      0.000000      0.000000\n","25%        1.000000      1.000000  ...      2.000000      2.000000\n","50%        1.000000      1.000000  ...      4.000000      2.000000\n","75%        1.000000      2.000000  ...      7.000000      4.000000\n","max       10.000000      8.000000  ...     19.000000     12.000000\n","\n","[8 rows x 34 columns]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"id":"O45y2DAsS4jk","executionInfo":{"status":"ok","timestamp":1635294227017,"user_tz":240,"elapsed":15,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"a755241e-2a22-4345-96b7-c449eb490e71"},"source":["df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bathrooms</th>\n","      <th>bedrooms</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>price</th>\n","      <th>interest_level_medium</th>\n","      <th>interest_level_low</th>\n","      <th>interest_level_high</th>\n","      <th>elevator</th>\n","      <th>cats_allowed</th>\n","      <th>hardwood_floors</th>\n","      <th>dogs_allowed</th>\n","      <th>doorman</th>\n","      <th>dishwasher</th>\n","      <th>no_fee</th>\n","      <th>laundry_in_building</th>\n","      <th>fitness_center</th>\n","      <th>pre-war</th>\n","      <th>laundry_in_unit</th>\n","      <th>roof_deck</th>\n","      <th>outdoor_space</th>\n","      <th>dining_room</th>\n","      <th>high_speed_internet</th>\n","      <th>balcony</th>\n","      <th>swimming_pool</th>\n","      <th>new_construction</th>\n","      <th>terrace</th>\n","      <th>exclusive</th>\n","      <th>loft</th>\n","      <th>garden_patio</th>\n","      <th>wheelchair_access</th>\n","      <th>common_outdoor_space</th>\n","      <th>total_perks</th>\n","      <th>total_rooms</th>\n","    </tr>\n","    <tr>\n","      <th>created</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2016-06-24 07:54:24</th>\n","      <td>1.5</td>\n","      <td>3</td>\n","      <td>40.7145</td>\n","      <td>-73.9425</td>\n","      <td>3000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4.5</td>\n","    </tr>\n","    <tr>\n","      <th>2016-06-12 12:19:27</th>\n","      <td>1.0</td>\n","      <td>2</td>\n","      <td>40.7947</td>\n","      <td>-73.9667</td>\n","      <td>5465</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-17 03:26:41</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>40.7388</td>\n","      <td>-74.0018</td>\n","      <td>2850</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-18 02:22:02</th>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>40.7539</td>\n","      <td>-73.9677</td>\n","      <td>3275</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2016-04-28 01:32:41</th>\n","      <td>1.0</td>\n","      <td>4</td>\n","      <td>40.8241</td>\n","      <td>-73.9493</td>\n","      <td>3350</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     bathrooms  bedrooms  ...  total_perks  total_rooms\n","created                                   ...                          \n","2016-06-24 07:54:24        1.5         3  ...            0          4.5\n","2016-06-12 12:19:27        1.0         2  ...            5          3.0\n","2016-04-17 03:26:41        1.0         1  ...            3          2.0\n","2016-04-18 02:22:02        1.0         1  ...            2          2.0\n","2016-04-28 01:32:41        1.0         4  ...            1          5.0\n","\n","[5 rows x 34 columns]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"SZH9ehW6M-BT"},"source":["# II. Split Data\n","\n","**Task 3:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'price'`.\n","\n","**Note:** In contrast to the last module project, this time you should include _all_ the numerical features in your dataset."]},{"cell_type":"code","metadata":{"id":"lpgjZmQ6M-BU"},"source":["X = df.drop(columns=['price'])\n","y = df['price']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aaAi0r2EM-BU"},"source":["**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n","\n","- Your training set should include data from April and May 2016. \n","- Your test set should include data from June 2016."]},{"cell_type":"code","metadata":{"id":"yNsNCSm4M-BV"},"source":["mask = (df.index >= \"2016-04-01\") & (df.index < \"2016-06-01\")\n","\n","X_train, y_train = X.loc[mask], y.loc[mask]\n","X_test, y_test = X.loc[~mask], y.loc[~mask]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IWE8BVqCM-BV"},"source":["# III. Establish Baseline"]},{"cell_type":"markdown","metadata":{"id":"hE4_sEBUM-BV"},"source":["**Task 5:** Since this is a **regression** problem, you need to calculate the baseline mean absolute error for your model. First, calculate the mean of `y_train`. Next, create a list `y_pred` that has the same length as `y_train` and where every item in the list is the mean. Finally, use `mean_absolute_error` to calculate your baseline."]},{"cell_type":"code","metadata":{"id":"U44rZSLCM-BW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635294227019,"user_tz":240,"elapsed":12,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"58a363d7-bfe1-4232-89aa-612e849495f4"},"source":["from sklearn.metrics import mean_absolute_error\n","\n","y_pred = [y_train.mean()] * len(y_train)\n","\n","baseline_mae = mean_absolute_error(y_train, y_pred)\n","print('Baseline MAE:', baseline_mae)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Baseline MAE: 1202.398300781848\n"]}]},{"cell_type":"markdown","metadata":{"id":"Knd2RMJfM-BW"},"source":["# IV. Build Model\n","\n","**Task 6:** Build and train a `LinearRegression` model named `model` using your feature matrix `X_train` and your target vector `y_train`."]},{"cell_type":"code","metadata":{"id":"0efvFQQhM-BW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635294227223,"user_tz":240,"elapsed":214,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"4edc3d85-9dfc-43ea-92ad-d950ab8a172e"},"source":["# Step 1: Import predictor class\n","from sklearn.linear_model import LinearRegression\n","\n","# Step 2: Instantiate predictor\n","model = LinearRegression()\n","\n","# Step 3: Fit predictor on the (training) data\n","model.fit(X_train,y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"6Lk7bTHGM-BX"},"source":["# V. Check Metrics\n","\n","**Task 7:** Calculate the training and test mean absolute error for your model."]},{"cell_type":"code","metadata":{"id":"96a7cB22M-BX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635294227224,"user_tz":240,"elapsed":12,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"cede4d83-dfff-44d5-ac41-54c0e95d0165"},"source":["training_mae = mean_absolute_error(y_train, model.predict(X_train))\n","test_mae = mean_absolute_error(y_test, model.predict(X_test))\n","\n","print('Training MAE:', training_mae)\n","print('Test MAE:', test_mae)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MAE: 672.9806423897443\n","Test MAE: 675.5598675712224\n"]}]},{"cell_type":"markdown","metadata":{"id":"GxFs4QrIM-BY"},"source":["**Task 8:** Calculate the training and test $R^2$ score for your model."]},{"cell_type":"code","metadata":{"id":"OP6tbn-CM-BY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635294227225,"user_tz":240,"elapsed":9,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"f41bcde6-8eb7-4f86-cbde-c6b56fe69b21"},"source":["training_r2 = model.score(X_train, y_train)\n","test_r2 = model.score(X_test, y_test)\n","\n","print('Training MAE:', training_r2)\n","print('Test MAE:', test_r2)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training MAE: 0.6369150317981817\n","Test MAE: 0.6490664473526142\n"]}]},{"cell_type":"markdown","metadata":{"id":"szZQmmR4M-BY"},"source":["# VI. Communicate Results\n","\n","**Stretch Goal:** What are the three most influential coefficients in your linear model? You should consider the _absolute value_ of each coefficient, so that it doesn't matter if it's positive or negative."]},{"cell_type":"code","metadata":{"id":"7qA0gFp8M-BY"},"source":["absolutes = np.abs(model.coef_)\n","best_cofficients = sorted(absolutes)[-3:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ChlSzKJrltFW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635294227434,"user_tz":240,"elapsed":214,"user":{"displayName":"german Parra Tovar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ging63pR7hoN9eEKOI8icWt19Mg31JZ1KXpnimcfw=s64","userId":"11017221582952699346"}},"outputId":"eff9bdc9-aa25-44cb-db51-579668efee7c"},"source":["# Import the feature selector utility\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","# Create the selector object with the best k=1 features\n","selector = SelectKBest(score_func=f_regression, k=3)\n","\n","# Run the selector on the training data\n","X_train_selected = selector.fit_transform(X_train, y_train)\n","\n","# Find the features that was selected\n","selected_mask = selector.get_support()\n","all_features = X_train.columns\n","selected_feature = all_features[selected_mask]\n","\n","print('The 3 Best Features are: ', list(selected_feature))\n","print('Best Features Coefficients:', best_cofficients)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The 3 Best Features are:  ['bathrooms', 'bedrooms', 'total_rooms']\n","Best Features Coefficients: [900195944122016.4, 900195944123227.8, 900195944123719.9]\n"]}]},{"cell_type":"code","metadata":{"id":"Lvll6BgbAAUk"},"source":[""],"execution_count":null,"outputs":[]}]}