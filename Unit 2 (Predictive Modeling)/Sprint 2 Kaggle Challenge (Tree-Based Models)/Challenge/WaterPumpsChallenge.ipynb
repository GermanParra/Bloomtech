{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "846448e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders==2.* in c:\\users\\gparr\\anaconda3\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (0.5.1)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (1.2.4)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (0.24.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from category_encoders==2.*) (0.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders==2.*) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders==2.*) (2021.1)\n",
      "Requirement already satisfied: six in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders==2.*) (1.15.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gparr\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install category_encoders==2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "836c35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "#from pandas_profiling import ProfileReport\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, validation_curve # k-fold CV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "72471489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(fm_path, tv_path=None):\n",
    "    if tv_path:\n",
    "        df = pd.merge(pd.read_csv(fm_path,\n",
    "                                  parse_dates=['date_recorded','construction_year'],\n",
    "                                  na_values=[0, -2.000000e-08]),\n",
    "                      pd.read_csv(tv_path))\n",
    "        df.set_index('id')\n",
    "\n",
    "        extra_elevations = pd.read_csv('Extra_Elevations - Extra_Elevations.csv')\n",
    "        extra_elevations.columns = ['id','gps_height']\n",
    "        df = df.merge(extra_elevations[['id', 'gps_height']], on='id', how='left')\n",
    "        gps_height_sum = df['gps_height_x'].fillna(0) + df['gps_height_y'].fillna(0)\n",
    "        df['gps_height_sum'] = gps_height_sum\n",
    "        df['gps_height_sum'] = df['gps_height_sum'].replace(0,np.nan)\n",
    "\n",
    "        df.drop(columns= ['gps_height_x','gps_height_y'], inplace=True)\n",
    "\n",
    "        #drop duplicate observations (rows)\n",
    "        df.drop_duplicates(inplace=True)  \n",
    "        \n",
    "    else:\n",
    "        df = pd.read_csv(fm_path,\n",
    "                         parse_dates=['date_recorded','construction_year'], \n",
    "                         na_values=[0, -2.000000e-08])\n",
    "        df = df.set_index('id')\n",
    "        \n",
    "        \n",
    "        extra_elevations = pd.read_csv('X_extra_X - X_extra_X.csv')\n",
    "        extra_elevations.columns = ['id','gps_height']\n",
    "        df = df.merge(extra_elevations[['id', 'gps_height']], on='id', how='left')\n",
    "        gps_height_sum = df['gps_height_x'].fillna(0) + df['gps_height_y'].fillna(0)\n",
    "        df['gps_height_sum'] = gps_height_sum\n",
    "        df['gps_height_sum'] = df['gps_height_sum'].replace(0,np.nan)\n",
    "\n",
    "        df.drop(columns= ['gps_height_x','gps_height_y'], inplace=True)\n",
    "        \n",
    "    # Drop constant columns\n",
    "    df.drop(columns=['recorded_by'], inplace=True)\n",
    "        \n",
    "    # Drop duplicate columns\n",
    "    dupe_cols = [col for col in df.head(100).T.duplicated().index\n",
    "                 if df.head(100).T.duplicated()[col]]\n",
    "    df.drop(columns=dupe_cols, inplace=True)    \n",
    "    \n",
    "    # Cleaning Extraction Type\n",
    "    swn_mask = df['extraction_type'].str.contains('swn')\n",
    "    df.loc[swn_mask,'extraction_type'] = 'swn'\n",
    "\n",
    "    india_mask = df['extraction_type'].str.contains('india mark')\n",
    "    df.loc[india_mask,'extraction_type'] = 'india mark'\n",
    "\n",
    "    rope_mask = df['extraction_type'].str.contains('rope pump')\n",
    "    df.loc[rope_mask,'extraction_type'] = 'rope pump'\n",
    "\n",
    "    Ex_types = df['extraction_type'].value_counts()[:11].index\n",
    "\n",
    "    Other_mask = df['extraction_type'].isin(Ex_types)\n",
    "    df.loc[~Other_mask,'extraction_type'] = 'other'\n",
    "\n",
    "    df.drop(columns=['extraction_type_group','extraction_type_class'], inplace=True)\n",
    "    \n",
    "    \n",
    "    # Cleaning source\n",
    "    Other_mask = df['source'].str.contains('unknown')\n",
    "    df.loc[Other_mask,'source'] = 'other'\n",
    "\n",
    "    df.drop(columns=['source_type','source_class'], inplace=True)\n",
    "    \n",
    "    # Cleaning Payment, Waterpoint, Water_Quality\n",
    "    df.drop(columns=['payment','waterpoint_type_group','quality_group'], inplace=True)\n",
    "\n",
    "    \n",
    "    # Cleaning Founders\n",
    "    df['funder'] = df['funder'].str.lower().fillna('other')\n",
    "\n",
    "    mask = df['funder'].str.contains('private')\n",
    "    df.loc[mask,'funder'] = 'private'\n",
    "\n",
    "    mask = df['funder'].str.contains('government')\n",
    "    df.loc[mask,'funder'] = 'government of tanzania'\n",
    "\n",
    "    mask = df['funder'].str.contains('danida')\n",
    "    df.loc[mask,'funder'] = 'danida'\n",
    "\n",
    "    mask = df['funder'].str.contains('hesawa')\n",
    "    df.loc[mask,'funder'] = 'hesawa'\n",
    "\n",
    "    mask = df['funder'].str.contains('rwssp')\n",
    "    df.loc[mask,'funder'] = 'rwssp'\n",
    "\n",
    "    mask = df['funder'].str.contains('bank')\n",
    "    df.loc[mask,'funder'] = 'bank'\n",
    "\n",
    "    mask = df['funder'].str.contains('ministry')\n",
    "    df.loc[mask,'funder'] = 'ministry'\n",
    "\n",
    "    mask = df['funder'].str.contains('germany')\n",
    "    df.loc[mask,'funder'] = 'germany'\n",
    "\n",
    "    mask = df['funder'].str.contains('church')\n",
    "    df.loc[mask,'funder'] = 'church'\n",
    "\n",
    "    mask = df['funder'].str.contains('unicef')\n",
    "    df.loc[mask,'funder'] = 'unicef'\n",
    "\n",
    "    mask = df['funder'].str.contains('council')\n",
    "    df.loc[mask,'funder'] = 'council'\n",
    "\n",
    "    mask = df['funder'].str.contains('rural water')\n",
    "    df.loc[mask,'funder'] = 'rwssp'\n",
    "\n",
    "    mask = df['funder'].str.contains('water')\n",
    "    df.loc[mask,'funder'] = 'water'\n",
    "\n",
    "    mask = df['funder'].str.contains('gov')\n",
    "    df.loc[mask,'funder'] = 'government of tanzania'\n",
    "\n",
    "    mask = df['funder'].str.contains('kkk')\n",
    "    df.loc[mask,'funder'] = 'kkkt'\n",
    "    \n",
    "    founders = df['funder'].value_counts()[:11].index\n",
    "    mask = df['funder'].isin(founders)\n",
    "    df.loc[~mask,'funder'] = 'other'\n",
    "    \n",
    "    df['installer'] = df['installer'].str.lower().fillna('other')\n",
    "\n",
    "    \n",
    "    #Cleaning Installers\n",
    "    mask = df['installer'].str.contains('private')\n",
    "    df.loc[mask,'installer'] = 'private'\n",
    "\n",
    "    mask = df['installer'].str.contains('government')\n",
    "    df.loc[mask,'installer'] = 'government of tanzania'\n",
    "\n",
    "    mask = df['installer'].str.contains('danida')\n",
    "    df.loc[mask,'installer'] = 'danida'\n",
    "\n",
    "    mask = df['installer'].str.contains('hesawa')\n",
    "    df.loc[mask,'installer'] = 'hesawa'\n",
    "\n",
    "    mask = df['installer'].str.contains('rwssp')\n",
    "    df.loc[mask,'installer'] = 'rwssp'\n",
    "\n",
    "    mask = df['installer'].str.contains('bank')\n",
    "    df.loc[mask,'installer'] = 'bank'\n",
    "\n",
    "    mask = df['installer'].str.contains('ministry')\n",
    "    df.loc[mask,'installer'] = 'ministry'\n",
    "\n",
    "    mask = df['installer'].str.contains('germany')\n",
    "    df.loc[mask,'installer'] = 'germany'\n",
    "\n",
    "    mask = df['installer'].str.contains('church')\n",
    "    df.loc[mask,'installer'] = 'church'\n",
    "\n",
    "    mask = df['installer'].str.contains('unicef')\n",
    "    df.loc[mask,'installer'] = 'unicef'\n",
    "\n",
    "    mask = df['installer'].str.contains('council')\n",
    "    df.loc[mask,'installer'] = 'council'\n",
    "\n",
    "    mask = df['installer'].str.contains('rural water')\n",
    "    df.loc[mask,'installer'] = 'rwssp'\n",
    "\n",
    "    mask = df['installer'].str.contains('water')\n",
    "    df.loc[mask,'installer'] = 'water'\n",
    "\n",
    "    mask = df['installer'].str.contains('gov')\n",
    "    df.loc[mask,'installer'] = 'government of tanzania'\n",
    "\n",
    "    mask = df['installer'].str.contains('kkk')\n",
    "    df.loc[mask,'installer'] = 'kkkt'\n",
    "\n",
    "    installer = df['installer'].value_counts()[:11].index\n",
    "    mask = df['installer'].isin(installer)\n",
    "    df.loc[~mask,'installer'] = 'other'\n",
    "\n",
    "    # Scheme Managment\n",
    "    df['scheme_management'] = df['scheme_management'].str.lower().fillna('other')\n",
    "    \n",
    "    mask = df['scheme_management'].str.contains('none')\n",
    "    df.loc[mask,'scheme_management'] = 'other'\n",
    "        \n",
    "    df.drop(columns=['management','scheme_name','wpt_name','num_private'], inplace=True)\n",
    "    \n",
    "    \n",
    "    # Adding ward Type\n",
    "    pop_data = pd.read_csv('tza_pop_popn_nbs_baselinedata.xlsx - baselinedata.csv')\n",
    "    pop_data = pop_data[['Ward_Name', 'ward_type']]\n",
    "    pop_data.columns = ['ward', 'ward_type']\n",
    "    df = df.merge(pop_data[['ward', 'ward_type']], on='ward', how='left')\n",
    "    df['ward_type'] = df['ward_type'].fillna('Unknown')\n",
    "    \n",
    "    \n",
    "    # DATES TO INTS TO OBJECTS\n",
    "    df['days_const_insp'] = pd.DatetimeIndex(df['date_recorded']) - pd.DatetimeIndex(df['construction_year'])\n",
    "    df['days_const_insp'] = round(df['days_const_insp'].astype('timedelta64[D]'), 3)\n",
    "    \n",
    "    \n",
    "    df['date_recorded'] = pd.DatetimeIndex(df['date_recorded']).year\n",
    "    df['construction_year'] = pd.DatetimeIndex(df['construction_year']).year\n",
    "\n",
    "    df['construction_year'] = df['construction_year'].astype('object')\n",
    "\n",
    "    \n",
    "    # HOURS OF USE\n",
    "    Hours_list = []\n",
    "    for val in df['population'].fillna(0):\n",
    "      if val == 0:\n",
    "        Hours_list.append(0)\n",
    "      elif val >= 800:\n",
    "        Hours_list.append(32)\n",
    "      elif (val >= 400) & (val < 800):\n",
    "        Hours_list.append(16)\n",
    "      elif (val >= 200) & (val < 400):\n",
    "        Hours_list.append(8)\n",
    "      elif (val >= 100) & (val < 200):\n",
    "        Hours_list.append(4)\n",
    "      else:\n",
    "        Hours_list.append(2)\n",
    "    df['Hours_per_day'] = Hours_list\n",
    "    df['Hours_per_day'] = df['Hours_per_day'].replace(0,np.nan)\n",
    "\n",
    "    df['Used_Hours'] = df['days_const_insp']*df['Hours_per_day']\n",
    "    \n",
    "    \n",
    "    \n",
    "    df.drop(columns=['region_code', 'ward', 'subvillage', 'region', 'district_code',\n",
    "                     'date_recorded','Hours_per_day'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "e763c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle('train_features.csv','train_labels.csv').set_index('id')\n",
    "X_test = wrangle('test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "2c53e65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 54816 entries, 454.0 to 23812.0\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   amount_tsh         16554 non-null  float64\n",
      " 1   funder             54816 non-null  object \n",
      " 2   installer          54816 non-null  object \n",
      " 3   longitude          53165 non-null  float64\n",
      " 4   latitude           53165 non-null  float64\n",
      " 5   basin              54816 non-null  object \n",
      " 6   lga                54816 non-null  object \n",
      " 7   population         35074 non-null  float64\n",
      " 8   public_meeting     51477 non-null  object \n",
      " 9   scheme_management  54816 non-null  object \n",
      " 10  permit             52015 non-null  object \n",
      " 11  construction_year  35529 non-null  object \n",
      " 12  extraction_type    54816 non-null  object \n",
      " 13  management_group   54816 non-null  object \n",
      " 14  payment_type       54816 non-null  object \n",
      " 15  water_quality      54816 non-null  object \n",
      " 16  quantity           54816 non-null  object \n",
      " 17  source             54816 non-null  object \n",
      " 18  waterpoint_type    54816 non-null  object \n",
      " 19  status_group       54816 non-null  object \n",
      " 20  gps_height_sum     53164 non-null  float64\n",
      " 21  ward_type          54816 non-null  object \n",
      " 22  days_const_insp    35529 non-null  float64\n",
      " 23  Used_Hours         34425 non-null  float64\n",
      "dtypes: float64(7), object(17)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "dffe50cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>population</th>\n",
       "      <th>gps_height_sum</th>\n",
       "      <th>days_const_insp</th>\n",
       "      <th>Used_Hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16554.000000</td>\n",
       "      <td>53165.000000</td>\n",
       "      <td>53165.000000</td>\n",
       "      <td>35074.000000</td>\n",
       "      <td>53164.000000</td>\n",
       "      <td>35529.000000</td>\n",
       "      <td>34425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1037.841951</td>\n",
       "      <td>35.218862</td>\n",
       "      <td>-5.953412</td>\n",
       "      <td>281.568712</td>\n",
       "      <td>1047.697451</td>\n",
       "      <td>5628.130935</td>\n",
       "      <td>42533.803980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5680.416417</td>\n",
       "      <td>2.626188</td>\n",
       "      <td>2.793186</td>\n",
       "      <td>589.131754</td>\n",
       "      <td>544.706838</td>\n",
       "      <td>4574.556937</td>\n",
       "      <td>64740.775776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>29.607122</td>\n",
       "      <td>-11.649440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-63.000000</td>\n",
       "      <td>-2405.000000</td>\n",
       "      <td>-28192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.280987</td>\n",
       "      <td>-8.662783</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>629.300000</td>\n",
       "      <td>1539.000000</td>\n",
       "      <td>6700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>35.078756</td>\n",
       "      <td>-5.417915</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1183.100000</td>\n",
       "      <td>4764.000000</td>\n",
       "      <td>19308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>600.000000</td>\n",
       "      <td>37.360256</td>\n",
       "      <td>-3.425971</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>1402.425000</td>\n",
       "      <td>9161.000000</td>\n",
       "      <td>47440.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>350000.000000</td>\n",
       "      <td>40.345193</td>\n",
       "      <td>-0.998464</td>\n",
       "      <td>30500.000000</td>\n",
       "      <td>2770.000000</td>\n",
       "      <td>19447.000000</td>\n",
       "      <td>609376.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          amount_tsh     longitude      latitude    population  \\\n",
       "count   16554.000000  53165.000000  53165.000000  35074.000000   \n",
       "mean     1037.841951     35.218862     -5.953412    281.568712   \n",
       "std      5680.416417      2.626188      2.793186    589.131754   \n",
       "min         0.200000     29.607122    -11.649440      1.000000   \n",
       "25%        50.000000     33.280987     -8.662783     40.000000   \n",
       "50%       200.000000     35.078756     -5.417915    150.000000   \n",
       "75%       600.000000     37.360256     -3.425971    320.000000   \n",
       "max    350000.000000     40.345193     -0.998464  30500.000000   \n",
       "\n",
       "       gps_height_sum  days_const_insp     Used_Hours  \n",
       "count    53164.000000     35529.000000   34425.000000  \n",
       "mean      1047.697451      5628.130935   42533.803980  \n",
       "std        544.706838      4574.556937   64740.775776  \n",
       "min        -63.000000     -2405.000000  -28192.000000  \n",
       "25%        629.300000      1539.000000    6700.000000  \n",
       "50%       1183.100000      4764.000000   19308.000000  \n",
       "75%       1402.425000      9161.000000   47440.000000  \n",
       "max       2770.000000     19447.000000  609376.000000  "
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "dbd443d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "31fd0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['status_group'])\n",
    "y = df['status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f7b96f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41112, 23), (13704, 23), (41112,), (13704,))"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X,y, random_state = 42)\n",
    "\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "5f3bec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "f56db7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 0.543880\n",
       "non functional             0.382248\n",
       "functional needs repair    0.073871\n",
       "Name: status_group, dtype: float64"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "30580166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy Score: 0.5438801323214634\n"
     ]
    }
   ],
   "source": [
    "baseline_acc = y_train.value_counts(normalize=True).max()\n",
    "print('Baseline Accuracy Score:', baseline_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "41708569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "9a17a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "d25c3276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Tuned Decision Tree Parameters: {'randomforestclassifier__n_estimators': 86, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__min_samples_leaf': 3, 'randomforestclassifier__max_samples': 0.3, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__max_depth': 39, 'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__bootstrap': False}\n",
      "Best score is 0.8058413393327658\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"randomforestclassifier__max_depth\": range(25, 50), #range(19,31,2),\n",
    "              \"randomforestclassifier__n_estimators\": range(85,100), #range(104,120,2),\n",
    "              \"randomforestclassifier__max_samples\":  [0.3,0.4,0.5],\n",
    "             \"randomforestclassifier__min_samples_split\": [5,6,7],\n",
    "              \"randomforestclassifier__min_samples_leaf\": [3],\n",
    "              \"randomforestclassifier__bootstrap\": [False],\n",
    "              \"randomforestclassifier__criterion\":['entropy','gini'],\n",
    "              \"randomforestclassifier__max_features\":['log2','sqrt'] #[0.3,0.4,0.5]\n",
    "             }\n",
    "model_rfrs = RandomizedSearchCV(\n",
    "    pipe_rf,\n",
    "    param_distributions = param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    "    verbose=1# status updates\n",
    ")\n",
    "\n",
    "# Fit it to the data\n",
    "model_rfrs.fit(X, y)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned Decision Tree Parameters: {}\".format(model_rfrs.best_params_))\n",
    "print(\"Best score is {}\".format(model_rfrs.best_score_))\n",
    "#Best score is 0.8083923896581758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40e219f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
